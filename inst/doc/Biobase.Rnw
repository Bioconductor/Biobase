%
% NOTE -- ONLY EDIT Biobase.Rnw!!!
% Biobase.tex file will get overwritten.
%
%\VignetteIndexEntry{Biobase Primer}
%\VignetteDepends{Biobase, genefilter, class, annotate, hgu95a}
%\VignetteKeywords{Expression Analysis}
%\VignettePackage{Biobase}
\documentclass{article}

\usepackage{hyperref}

\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\classdef}[1]{%
  {\em #1}
}

\begin{document}
\title{Textual Description of Biobase}
\maketitle

\section*{Introduction}

Biobase is part of the Bioconductor project. It is meant to be the
location of any reusable (or non--specific) functionality.
Biobase will be required by most of the other Bioconductor libraries.

\section{Data Structures}

Part of the Biobase functionality is the standardization of data
structures for genomic data.
Currently we have designed some data structures to handle microarray
data.

The \classdef{exprSet} class has the following slots:
\begin{description}
\item[exprs] A matrix of expression levels. Arrays are columns and
  genes are rows.
\item[se.exprs] A matrix of standard errors for expressions if they
                          are available. It will have length 0 if they
                          are not.
\item[phenoData] An object of class \verb+phenoData+ that contains
  phenotypic and/or experimental data.
\item[description] A description of the experiment (object of class MIAME)
\item[annotation] A character string indicating the base name for the
  associated annotation.
\item[notes] A set of notes describing aspects or features of the data,
  the analysis, processing done, etc.
\end{description}

These data are extremely large and complex. To deal with them
effectively we will need better tools for combining data and
documentation. The \verb+exprSet+ class represents an initial attempt
by the Bioconductor project to provide better tools for documenting
and handling these large and complex data sets.

Biologically relevant data will be availabe through the
{\em annotation} package. Special modules containing information
(such as gene name, symbol, chromosomal location) can be constructed.
These data can then be linked to the \verb+exprSet+ via the
\verb+annotation+ slot.

The \verb+phenoData+ class has the following slots:
\begin{description}
\item[pData] A dataframe where the rows are cases and the columns are
  variables.
\item[varLabels] A list of labels and descriptions for the variables
  represented by the columns of \verb+pData+.
\end{description}

Instances of this class are essentially \verb+data.frame+'s with some
additional documentation on the variables stored in the
\verb+varLabels+ slot.

A mechanism for ensuring that the elements of the \verb+phenoData+
slot of an instance of \verb+exprSet+ are in the same order as the
columns of the \verb+exprs+ array is needed. It is important that these be
properly aligned since analyses will require this and automatic tools
for checking will probably be better than ad hoc ones.

In addition to the class definitions a number of special methods (or
functions) have been defined to operate on instances of these classes.
Some particular attention has been paid to subsetting operations.
Instances of both \verb+phenoData+ and \verb+exprSet+ are closed under
subsetting operations.
That is, any subset of one of these objects retains its class.
There are also specialized print methods for objects of both classes.

We consider an instance of an \verb+exprSet+ to be an expression array
with some additional information. Thus there are two subscripts, one
for the rows and one for the columns.
For that reason subsetting works in the following ways:
\begin{itemize}
\item If the first subscript is given then the appropriate subset
  of rows from \verb+exprs+ and \verb+se.exprs+ is taken. All the data
  in \verb+phenoData+ is propagated since no subset of cases was made.
\item If the second subscript is given then the appropriate set of
  columns from \verb+exprs+ and \verb+se.exprs+ is taken. At the same
  time the corresponding set of {\em rows} of \verb+phenoData+ are
  taken.
\end{itemize}

\subsection{An exprSet Vignette}

In the data directory for Biobase there is a small anonymized data
set. It consists of expression level data for 500 genes on 26
patients. The data can be accessed with the command
\verb+data(geneData)+.
There are three artificial covariates provided as well.
These can be accessed using \verb+data(geneCov)+ once the Biobase
library is attached.
The following vignette shows how to read in these data and to create
an instance of the \verb+exprSet+ class using those data.

<<R.hide, echo=F>>=
library(Biobase)
@
%junk

<<R>>=
data(geneCov)
data(geneData)
covN <- list(cov1 = "Covariate 1; 2 levels",
             cov2 = "Covariate 2; 2 levels",
             cov3 = "Covariate 3; 3 levels")

pD <- new("phenoData", pData=geneCov, varLabels=covN)
eSet <- new("exprSet", exprs=geneData, phenoData=pD)

@

\section{Aggregate}

When performing an interative computation such as cross--validation or
bootstrapping it is often useful to be able to aggregate certain intermediate
results.
The \verb+Aggregate+ functions (and soon the Aggregate class) provide
some simple tools for doing this.

The strategy employed is to maintain the summary statistics in an
environment. This is passed to the iterative function. It does not
need to be returned since environments have a {\em
  pass--by--reference} semantic. Once the function has finished the
environment can be queried for the summary statistics.

One simple task that people often want to carry out is to determine in
a cross--validation calculation which genes are selected the most
often. In some sense these genes may form a more stable basis for
inference.
Achieving that using an Aggregator is very straight forward.

At each iteration we will pass the names of the selected genes to the
Aggregator. It has two functions, one for initializing and one for
updating (or aggregating). The aggregator also has an environment.
This environment stores the data that is being aggregated.

For our cross--validation example the process goes as follows:
\begin{enumerate}
\item At each iteration Aggregate is called with the list of genes
  selected.
\item For each gene in that list we check to see if it was selected
  before.
  \begin{enumerate}
  \item If not then \verb+initfun+ is called with that gene name.
        The value returned by \verb+initfun+ is then associated with
        the gene name in the aggregation environment.
  \item If so, then the current value is obtained and \verb+agfun+ is
    called with the the gene name and the current value. This returns
    a new value that is then associated with the gene name in the
    aggregation environment.
  \end{enumerate}
\end{enumerate}

Basically we are using this as a form of updating hash table.
At the same time we are slightly subverting R's usual pass--by--value
semantics.

\section{Aggregate Vignette}

The function given below performs k--nearest neighbour classification
using leave--one--out cross--validation.
At the same time it aggregates the genes that were selected. The
function returns the predicted classifications as its returned
value. However, there is an additional side effect. The number of
times that each gene was used (provided it was at least one) are
recorded and stored in the environment of the aggregator \verb+Agg+.
These can subsequently be retrieved and used for other purposes.

<<aggregate>>=

 knnCV <- function(EXPR, selectfun, cov, Agg, pselect = 0.01, Scale=FALSE) {
   nc <- ncol(EXPR)
   outvals <- rep(NA, nc)
   for(i in 1:nc) {
      v1 <- EXPR[,i]
      expr <- EXPR[,-i]
      glist <- selectfun(expr, cov[-i], p=pselect)
      expr <- expr[glist,]
      if( Scale ) {
        expr <- scale(expr)
        v1 <- as.vector(scale(v1[glist]))
      }
      else
         v1 <- v1[glist]
      out <- paste("iter ",i, " num genes= ", sum(glist), sep="")
      print(out)
      Aggregate(row.names(expr), Agg)
      if( length(v1) == 1)
         outvals[i] <- knn(expr, v1, cov[-i], k=5)
      else
          outvals[i] <- knn(t(expr), v1, cov[-i], k=5)
    }
    return(outvals)
  }
@
%$

Next we provide a simple gene filtering function (this requires the
genefilter library).

<<aggregate>>=
 gfun <- function(expr, cov, p=0.05) {
    f2 <- ttest(cov, p=p)
    ffun <- filterfun(f2)
    which <- genefilter(expr, ffun)
  }

@

Next we show how to use this function on the system dataset,
\verb+geneData+.

<<aggregate>>=
  library(genefilter)
  library(class)

  data(eset)

  ##scale the genes
  ##genescale is a slightly more flexible "scale"
  ##work on a subset -- for speed only
  geneData <- genescale(exprs(eset)[1:75,], 1)

  Agg <- new("aggregator")

  testcase <- knnCV(geneData, gfun, eset$cov2, Agg, pselect=0.05)

  genes.used <- multiget(ls(env=aggenv(Agg)), env=aggenv(Agg))
  genes.counts <- as.numeric(genes.used)
  names(genes.counts) <- names(genes.used)
  sort(genes.counts)
@
%$
  The variable \verb+genes.counts+ now contains, for each gene,
  the number of times it was selected in the cross-validation.

  One may also compare testcase with geneCov to see how well the
  procedure worked at predicting.


%\section*{Resampling exprSet's}
%need to fill this in again


\end{document}





