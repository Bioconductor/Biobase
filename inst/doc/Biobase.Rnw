%
% NOTE -- ONLY EDIT Biobase.Rnw!!!
% Biobase.tex file will get overwritten.
%
%\VignetteIndexEntry{Biobase Primer}
%\VignetteDepends{Biobase, genefilter, class, annotate, hgu95a}
%\VignetteKeywords{Expression Analysis}

\documentclass{article}

\usepackage{hyperref}

\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\classdef}[1]{%
  {\em #1}
}

\begin{document}
\title{Textual Description of Biobase}
\maketitle

\section*{Introduction}

Biobase is part of the Bioconductor project. It is meant to be the
location of any reusable (or non--specific) functionality.
Biobase will be required by most of the other Bioconductor libraries.

\section{Data Structures}

Part of the Biobase functionality is the standardization of data
structures for genomic data.
Currently we have designed some data structures to handle microarray
data.

The \classdef{exprSet} class has the following slots:
\begin{description}
\item[exprs] A matrix of expression levels. Arrays are columns and
  genes are rows.
\item[se.exprs] A matrix of standard errors for expressions (may be
  \verb+NULL+) if they are available.
\item[phenoData] An object of class \verb+phenoData+ that contains
  phenotypic or experimental data.
\item[description] A description of the experiment (object of class miame)
\item[annotation] A character string indicating the base name for the
  associated annotation.
\item[notes] A set of notes describing aspects or features of the data,
  the analysis, processing done, etc.
\end{description}

These data are extremely large and complex. To deal with them
effectively we will need better tools for combining data and
documentation. The \verb+exprSet+ class represents an initial attempt
by the Bioconductor project to provide better tools for documenting
and handling these large and complex data sets.

Biologically relevant data will be availabe through the
{\em annotation} package. Special modules containing information
(such as gene name, symbol, chromosomal location) can be constructed.
These data can then be linked to the \verb+exprSet+ via the
\verb+annotation+ slot.


The \verb+phenoData+ class has the following slots:
\begin{description}
\item[pData] A dataframe where the rows are cases and the columns are
  variables.
\item[varLabels] A list of labels and descriptions for the variables
  represented by the columns of \verb+pData+.
\end{description}

Instances of this class are essentially \verb+data.frame+'s with some
additional documentation on the variables stored in the
\verb+varLabels+ slot.

A mechanism for ensuring that the elements of the \verb+phenoData+
slot of an instance of \verb+exprSet+ are in the same order as the
columns of the \verb+exprs+ array is needed. It is important that these be
properly aligned since analyses will require this and automatic tools
for checking will probably be better than ad hoc ones.

In addition to the class definitions a number of special methods (or
functions) have been defined to operate on instances of these classes.
Some particular attention has been paid to subsetting operations.
Instances of both \verb+phenoData+ and \verb+exprSet+ are closed under
subsetting operations.
That is, any subset of one of these objects retains its class.
There are also specialized print methods for objects of both classes.

We consider an instance of an \verb+exprSet+ to be an expression array
with some additional information. Thus there are two subscripts, one
for the rows and one for the columns.
For that reason subsetting works in the following ways:
\begin{itemize}
\item If the first subscript is given then the appropriate subset
  of rows from \verb+exprs+ and \verb+se.exprs+ is taken. All the data
  in \verb+phenoData+ is propagated since no subset of cases was made.
\item If the second subscript is given then the appropriate set of
  columns from \verb+exprs+ and \verb+se.exprs+ is taken. At the same
  time the corresponding set of {\em rows} of \verb+phenoData+ are
  taken.
\end{itemize}

\subsection{An exprSet Vignette}

In the data directory for Biobase there is a small anonymized data
set. It consists of expression level data for 500 genes on 26
patients. The data can be accessed with the command
\verb+data(geneData)+.
There are three artificial covariates provided as well.
These can be accessed using \verb+data(geneCov)+ once the Biobase
library is attached.
The following vignette shows how to read in these data and to create
an instance of the \verb+exprSet+ class using those data.

<<R.hide, echo=F>>=
library(Biobase)
@
%junk

<<R>>=
data(geneCov)
data(geneData)
covN <- list(cov1 = "Covariate 1; 2 levels",
             cov2 = "Covariate 2; 2 levels",
             cov3 = "Covariate 3; 3 levels")

pD <- new("phenoData", pData=geneCov, varLabels=covN)
eSet <- new("exprSet", exprs=geneData, phenoData=pD)

@

\section{Aggregate}

When performing an interative computation such as cross--validation or
bootstrapping it is often useful to be able to aggregate certain intermediate
results.
The \verb+Aggregate+ functions (and soon the Aggregate class) provide
some simple tools for doing this.

The strategy employed is to maintain the summary statistics in an
environment. This is passed to the iterative function. It does not
need to be returned since environments have a {\em
  pass--by--reference} semantic. Once the function has finished the
environment can be queried for the summary statistics.

One simple task that people often want to carry out is to determine in
a cross--validation calculation which genes are selected the most
often. In some sense these genes may form a more stable basis for
inference.
Achieving that using an Aggregator is very straight forward.

At each iteration we will pass the names of the selected genes to the
Aggregator. It has two functions, one for initializing and one for
updating (or aggregating). The aggregator also has an environment.
This environment stores the data that is being aggregated.

For our cross--validation example the process goes as follows:
\begin{enumerate}
\item At each iteration Aggregate is called with the list of genes
  selected.
\item For each gene in that list we check to see if it was selected
  before.
  \begin{enumerate}
  \item If not then \verb+initfun+ is called with that gene name.
        The value returned by \verb+initfun+ is then associated with
        the gene name in the aggregation environment.
  \item If so, then the current value is obtained and \verb+agfun+ is
    called with the the gene name and the current value. This returns
    a new value that is then associated with the gene name in the
    aggregation environment.
  \end{enumerate}
\end{enumerate}

Basically we are using this as a form of updating hash table.
At the same time we are slightly subverting R's usual pass--by--value
semantics.

\section{Aggregate Vignette}

The function given below performs k--nearest neighbour classification
using leave--one--out cross--validation.
At the same time it aggregates the genes that were selected. The
function returns the predicted classifications as its returned
value. However, there is an additional side effect. The number of
times that each gene was used (provided it was at least one) are
recorded and stored in the environment of the aggregator \verb+Agg+.
These can subsequently be retrieved and used for other purposes.

<<aggregate>>=

 knnCV <- function(EXPR, selectfun, cov, Agg, pselect = 0.01, Scale=FALSE) {
   nc <- ncol(EXPR)
   outvals <- rep(NA, nc)
   for(i in 1:nc) {
      v1 <- EXPR[,i]
      expr <- EXPR[,-i]
      glist <- selectfun(expr, cov[-i], p=pselect)
      expr <- expr[glist,]
      if( Scale ) {
        expr <- scale(expr)
        v1 <- as.vector(scale(v1[glist]))
      }
      else
         v1 <- v1[glist]
      out <- paste("iter ",i, " num genes= ", sum(glist), sep="")
      print(out)
      Aggregate(row.names(expr), Agg)
      if( length(v1) == 1)
         outvals[i] <- knn(expr, v1, cov[-i], k=5)
      else
          outvals[i] <- knn(t(expr), v1, cov[-i], k=5)
    }
    return(outvals)
  }
@
%$

Next we provide a simple gene filtering function (this requires the
genefilter library).

<<aggregate>>=
 gfun <- function(expr, cov, p=0.05) {
    f2 <- ttest(cov, p=p)
    ffun <- filterfun(f2)
    which <- genefilter(expr, ffun)
  }

@

Next we show how to use this function on the system dataset,
\verb+geneData+.

<<aggregate>>=
  library(genefilter)
  library(class)

  data(eset)

  ##scale the genes
  ##genescale is a slightly more flexible "scale"
  ##work on a subset -- for speed only
  geneData <- genescale(exprs(eset)[1:75,], 1)

  Agg <- new("aggregator")

  testcase <- knnCV(geneData, gfun, eset$cov2, Agg, pselect=0.05)

  genes.used <- multiget(ls(env=aggenv(Agg)), env=aggenv(Agg))
  genes.counts <- as.numeric(genes.used)
  names(genes.counts) <- names(genes.used)
  sort(genes.counts)
@

  The variable \verb+genes.counts+ now contains, for each gene,
  the number of times it was selected in the cross-validation.

  One may also compare testcase with geneCov to see how well the
  procedure worked at predicting.

\section{HTML page Vignette}

In this section we give a simple example of how to produce a HTML web
page with links to Locus Link etc.

First we have a small helper function that can be used to create two
sample tests suitable for applying (or other things). It returns the
test statistic and {\em p--value}.

<<HTML>>=
  mk2samp<- function(cov, testfun) {
      function(x) {
          nas <- is.na(x)
          if( length(levels(factor(cov[!nas]))) != 2 )
              return(c(NA,NA))
          tmp <- testfun(x~cov)
          return(c(tmp$statistic, tmp$p.value))
      }
  }
@

I also needed to add the next two helper functions. These should get
fixed and placed into the library.

<<HTML>>=

 HTtable <- function(content, caption ) {
    head <- paste("<TABLE BORDER=4>", "<CAPTION>", caption, "</CAPTION>")
    tail <- paste("</TABLE>")
    c(head, content, tail)
 }

 HTpage <- function(filename, content, title="BioConductor Gene Listing",
   center=TRUE)  {
  outfile <- file(filename, "w")
  cat("<html>", "<head>", "<TITLE>BioConductor Gene Listing</TITLE>",
  "</head>", "<body bgcolor=#708090 >",
  "<H1 ALIGN=CENTER > BioConductor Gene Listing </H1>",
            file = outfile, sep = "\n")
  cat(content, file=outfile, sep="\n")
   cat("</body>", "</html>", sep = "\n", file = outfile)
    close(outfile)
  }

@


<<HTML>>=

 library(Biobase)
 library(annotate)
 data(eset)

 sub1<- exprs(eset)[140:150,]
 ttfun <- mk2samp(eset$cov1, t.test)
 outvals <- t(apply(sub1, 1, ttfun))

 ##set up a translator
 library(hgu95a)
 llnames <- multiget(dimnames(outvals)[[1]], env=hgu95aLOCUSID)
 llnames <- as.character(llnames)
 names(llnames) <- dimnames(outvals)[[1]]

 ## now we need to set up the functions to create the HTML page

 LLAnch <- function(x) simpleAnchor(x, hMethod=
 "http://www.ncbi.nlm.nih.gov/LocusLink/LocRpt.cgi?l=")

 anch.llnames<- LLAnch(llnames)

 pvals <- HTwrap(round(outvals[,2],3))
 tstats <- HTwrap(round(outvals[,1],3))
 anch.ll <- HTwrap(anch.llnames)
 allvals <- paste(anch.ll, pvals, tstats, sep="\n")
 inlist <- HTwrap(allvals, "TR")
 header<- HTwrap(paste(HTwrap("Locus Link"), HTwrap("p-values"),
 HTwrap("t-stats")), "TR")
 tbl <- HTtable(c(header, inlist), "Genes")
 HTpage("test.html", tbl, "Hello")

@

\section*{Resampling exprSet's}

There are many examples of situations where resampling
(eg. cross--validation or bootstrapping) of \classdef{exprSet}'s is an
important part of the analysis.
In this section we consider some tools designed to simplify the
operation of resampling \classdef{exprSet}'s.

The general strategy for an analysis is
\begin{enumerate}
\item Filter the genes in the \classdef{exprSet} according to a
specific criterion. The criterion will be encapsulated in the
\verb+filterB+ function.
\item Next the function \verb+ifun+ is applied to the result of the
filtering criterion. In some cases \verb+ifun+ will need to depend on
covariates or other features of the \classdef{exprSet}.
\end{enumerate}

Code demonstrating a couple of simple examples is given next.
In the first example genefiltering will extract those genes for which
at least 5 of the samples have expression levels over 250 and where a
t--test (using \verb+cov2+ from the data set) has a $p$--value of less
than 0.1.
Intermediate functions are stored in the variable \verb+fb1+.

The function \verb+fbuilder+ takes the necessary information to build
a set of filter functions from any \classdef{exprSet}.
The argument \verb+sub="m"+ indicates the name of the variable that we
will do substitution on (we need to replace that variables symbol with
the name \verb+cov2+.

In this first example the updating function does nothing and while it
is required it simply returns \verb+NULL+ given any \classdef{exprSet}
and any filtering function.


<<cvExprset>>=
library(Biobase)
library(genefilter)

data(eset)
fb1 <- fbuilder(list(
     list(funname="ttest", args=list(m="cov2", p=.1), sub="m"),
     list(funname="kOverA", args=list(k=5, A=250))))

##updating function doesn't need to do anything
upd1 <- function(ESET, fun) NULL

test1 <- filtertheniter(eset, fb1, mean, upd1)

afun<-AnovaF(cov3)

updf <- function(ESET, fun) assign("cov", ESET$cov3, env=environment(fun))

test2 <- filtertheniter(eset, fb1, afun, updf)

assign("cov", eset$cov3, env=environment(afun))

fb2<- fbuilder(list(
    list(funname="kOverA", args=list(A=250))))
@

%$

\end{document}





